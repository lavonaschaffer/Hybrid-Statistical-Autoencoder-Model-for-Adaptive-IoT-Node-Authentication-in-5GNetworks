{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 1: Autoencoder Training for RF Fingerprinting\n",
        "\n",
        "This notebook trains the deep convolutional autoencoder on Google Colab with GPU support.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Enable GPU and Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Enable GPU in Colab\n",
        "# Runtime -> Change runtime type -> Hardware accelerator -> GPU\n",
        "\n",
        "# Check if GPU is available\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "%pip install numpy h5py scikit-learn tqdm matplotlib seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy file from Drive to project directory\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Path in your Google Drive where you uploaded the file\n",
        "drive_file_path = '/content/drive/MyDrive/radioml_2018_processed.npz'  # Adjust path as needed\n",
        "target_path = 'ML_Project/data/processed/radioml_2018_processed.npz'\n",
        "\n",
        "if os.path.exists(drive_file_path):\n",
        "    shutil.copy(drive_file_path, target_path)\n",
        "    print(f\"✓ File copied from Drive to {target_path}\")\n",
        "else:\n",
        "    print(f\"✗ File not found at {drive_file_path}\")\n",
        "    print(\"Please upload the file to Google Drive first, then update the path above\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Upload Project Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create directory structure\n",
        "import os\n",
        "os.makedirs('ML_Project/src/models', exist_ok=True)\n",
        "os.makedirs('ML_Project/src/utils', exist_ok=True)\n",
        "os.makedirs('ML_Project/data/processed', exist_ok=True)\n",
        "os.makedirs('ML_Project/saved_models', exist_ok=True)\n",
        "\n",
        "print(\"Directory structure created. Please upload the following files:\")\n",
        "print(\"1. src/models/autoencoder.py\")\n",
        "print(\"2. src/train_ae.py\")\n",
        "print(\"3. data/processed/radioml_2018_processed.npz\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload processed data file\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "print(\"Please upload the processed data file (radioml_2018_processed.npz)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.npz'):\n",
        "        shutil.move(filename, f'ML_Project/data/processed/{filename}')\n",
        "        print(f\"Moved {filename} to ML_Project/data/processed/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Upload Source Code Files\n",
        "\n",
        "**Method 1: Upload individual files** (for small files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload Python files\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Upload autoencoder.py\n",
        "print(\"Upload src/models/autoencoder.py\")\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    if 'autoencoder' in filename:\n",
        "        shutil.move(filename, 'ML_Project/src/models/autoencoder.py')\n",
        "        print(f\"✓ Uploaded autoencoder.py\")\n",
        "\n",
        "# Upload train_ae.py  \n",
        "print(\"\\nUpload src/train_ae.py\")\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    if 'train_ae' in filename:\n",
        "        shutil.move(filename, 'ML_Project/src/train_ae.py')\n",
        "        print(f\"✓ Uploaded train_ae.py\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Method 2: Clone from GitHub** (recommended)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If your project is on GitHub, clone it:\n",
        "# !git clone https://github.com/yourusername/your-repo.git\n",
        "# %cd your-repo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Verify Setup and Train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check required files\n",
        "required_files = [\n",
        "    'ML_Project/src/models/autoencoder.py',\n",
        "    'ML_Project/src/train_ae.py',\n",
        "    'ML_Project/data/processed/radioml_2018_processed.npz'\n",
        "]\n",
        "\n",
        "print(\"Checking required files...\")\n",
        "all_ok = True\n",
        "for file_path in required_files:\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"✓ {file_path}\")\n",
        "    else:\n",
        "        print(f\"✗ {file_path} - MISSING!\")\n",
        "        all_ok = False\n",
        "\n",
        "if all_ok:\n",
        "    print(\"\\n✓ All files are ready!\")\n",
        "else:\n",
        "    print(\"\\n✗ Please upload the missing files!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Change to project directory and train\n",
        "%cd ML_Project\n",
        "\n",
        "# Add src to Python path\n",
        "import sys\n",
        "sys.path.insert(0, 'src')\n",
        "\n",
        "# Import and run training\n",
        "# Code will automatically use GPU if available\n",
        "from train_ae import train_model\n",
        "\n",
        "print(\"Starting training...\")\n",
        "print(\"Code will automatically use GPU if available\")\n",
        "train_model()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Download Trained Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download model weights to local machine\n",
        "from google.colab import files\n",
        "\n",
        "if os.path.exists('saved_models/ae_weights.pth'):\n",
        "    files.download('saved_models/ae_weights.pth')\n",
        "    print(\"✓ Model downloaded successfully!\")\n",
        "else:\n",
        "    print(\"✗ Model file not found. Training may not have completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tips for Training on Colab\n",
        "\n",
        "1. **Enable GPU**: Runtime → Change runtime type → Hardware accelerator → GPU\n",
        "2. **Monitor GPU**: Run `!nvidia-smi` to check GPU usage\n",
        "3. **Save progress**: \n",
        "   - Colab sessions disconnect after inactivity. Make sure to:\n",
        "   - Download model immediately after training completes\n",
        "   - Or save to Google Drive\n",
        "4. **Increase batch size**: If GPU has more memory, you can increase `batch_size` in CONFIG\n",
        "5. **Time limits**: Free Colab has ~12 hour session limits. Consider:\n",
        "   - Training fewer epochs initially for testing\n",
        "   - Using early stopping\n",
        "   - Saving checkpoints periodically\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
